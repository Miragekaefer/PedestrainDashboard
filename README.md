# Pedestrian Prediction System

Dieses Repository stellt ein vollstÃ¤ndiges Passanten-Analytics-System fÃ¼r WÃ¼rzburg bereit. Es kombiniert historische Messungen, aktuelle Datenfeeds, Wettervorhersagen sowie Event- und Kalenderinformationen, um Prognosen zu erzeugen und sie in einem modernen Dashboard aufzubereiten.

Das Projekt besteht aus einem FastAPI-Backend mit Redis als Zeitreihen-Store, einem Next.js 15 Frontend fÃ¼r Visual Analytics und einem ML-Stack zur Generierung stÃ¼ndlicher Vorhersagen (bis zu acht Tage in die Zukunft).

## Highlights

- Echtzeit- und historische Visualisierung mit Next.js 15, React 19, Tailwind und shadcn/ui (`frontend/components/dashboard.tsx`)
- Aggregierte Statistiken, Trendprognosen, Heatmaps und Kalenderereignisse in einer OberflÃ¤che (`frontend/components/charts`, `statistics`, `calendar`)
- FastAPI-Backend mit umfangreichen Endpoints fÃ¼r Zeitreihen, Events, Kalender und Standortdaten (`backend/api/main.py`)
- Automatisierte Daten-Pipeline inkl. CSV-Import, Open-Data-Fetcher und stÃ¼ndlicher Scheduler fÃ¼r ML-Vorhersagen (`backend/scripts/initial_load.py`, `data_ingestion/scheduler.py`)
- Containerisierte Laufzeit mittels `compose.yaml` (Redis Stack, Data Loader, Scheduler, API)

## Gesamtarchitektur

```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚       Next.js 15         â”‚
                   â”‚  (App Router Dashboard)  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚ REST
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Stack    â”‚â—„â”€â”€â–ºâ”‚ FastAPI (`api/main`)  â”‚
â”‚  (Zeitreihen &  â”‚    â”‚  - Daten & Prognosen  â”‚
â”‚   Feature Store)â”‚    â”‚  - Swagger / ReDoc    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                         â”‚
         â”‚                         â”‚ ruft
         â”‚ writes/reads            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Loader     â”‚        â”‚ Scheduler & ML      â”‚
â”‚ (`scripts/...`) â”‚        â”‚ (`data_ingestion/`  â”‚
â”‚  - CSV Import   â”‚        â”‚  + `ML/predict.py`) â”‚
â”‚  - API Fetcher  â”‚        â”‚  - StÃ¼ndliche Jobs  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Repository Aufbau

```
backend/
  api/                  # FastAPI App & Endpoints
  database/             # Redis Client & Zugriff
  data_ingestion/       # Open-Data Fetcher & Scheduler
  ML/                   # Training & Prediction Pipelines
  scripts/              # CSV-Import, Initial Loader, Indexbuilder
  data/                 # Erwartete CSV-Dateien (nicht eingecheckt)
  requirements.txt      # Python-AbhÃ¤ngigkeiten
  Dockerfile

frontend/
  app/                  # Next.js App Router Einstieg
  components/           # Dashboard, Charts, Filter, UI
  lib/                  # API-Client, Types, Hooks
  public/
  package.json

compose.yaml            # Docker Compose Stack (Redis + Backend Services)
```

## Schnellstart

### Voraussetzungen

- Docker & Docker Compose (oder Podman Compose)
- Node.js â‰¥ 20 (fÃ¼r lokale Frontend-Entwicklung mit Turbopack)
- Python 3.11 (nur falls Backend ohne Container betrieben werden soll)
- Eigener OpenWeather API-Key fÃ¼r Prognosen (kostenlos erhÃ¤ltlich unter https://openweathermap.org/)

### 1. Umgebungsvariablen anlegen

Erstelle im Projektroot eine `.env` (fÃ¼r Backend & Compose):

```bash
OPENWEATHER_API_KEY=<dein_openweather_api_key>
REDIS_HOST=redis
REDIS_PORT=6379
```

FÃ¼r das Frontend wird eine `frontend/.env.local` benÃ¶tigt:

```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

### 2. CSV-Daten bereitstellen

Lege die Rohdaten in `backend/data/` ab. Erwartet werden u.â€¯a.:

- `dataAllStreets.csv` â€“ historische PassantenzÃ¤hlungen (stÃ¼ndlich)
- `counterGeoLocations.csv` â€“ ZÃ¤hlstellen inklusive Geometrie
- `bavarian_public_holidays*.csv`, `bavarian_school_holidays*.csv`
- `events.csv`, `events_daily.csv`
- `lectures.csv`, `lectures_daily.csv`

Siehe Abschnitt [Datenpipeline & Machine Learning](#datenpipeline--machine-learning) fÃ¼r Details zu den Formaten.

### 3. Stack starten (empfohlener Weg)

```bash
# Repository klonen
git clone <repository-url>
cd PedestrainDashboard - Kopie

# Container bauen & starten
docker compose up -d --build

# Logs ansehen
docker compose logs -f --tail=50
```

Nach wenigen Minuten (Initialimport + erste Prognose) stehen folgende URLs zur VerfÃ¼gung:

- Dashboard: http://localhost:3000
- FastAPI + Swagger: http://localhost:8000 /docs
- Redis Insight (Visualisierung der Keys): http://localhost:8001

Compose-Services:

- `redis` â€“ Redis Stack (inkl. Insight UI)
- `data_loader` â€“ einmaliger CSV-/API-Import (`scripts/initial_load.py`)
- `scheduler` â€“ stÃ¼ndliche Updates + ML-Vorhersagen (`data_ingestion/scheduler.py`)
- `api` â€“ FastAPI mit `uvicorn --reload`

### 4. Frontend im Dev-Modus (optional)

```bash
cd frontend
npm install
npm run dev  # lÃ¤uft auf http://localhost:3000
```

Durch das Volume-Mounting in `compose.yaml` kÃ¶nnen Frontend-/Backend-Dateien direkt bearbeitet werden; Hot Reload sorgt fÃ¼r schnelle Iteration.

## Manuelle Entwicklung ohne Docker

1. Redis starten (z.â€¯B. lokal `redis-stack` auf Port 6379/8001)
2. Backend-AbhÃ¤ngigkeiten installieren:
   ```bash
   cd backend
   python -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   ```
3. Initiale Daten laden:
   ```bash
   python scripts/initial_load.py
   ```
4. API starten:
   ```bash
   uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
   ```
5. Scheduler (fÃ¼r kontinuierliche Updates) separat ausfÃ¼hren:
   ```bash
   python -m data_ingestion.scheduler
   ```
6. Frontend wie oben starten (`npm run dev`).

## Backend Komponenten

- `backend/api/main.py`: Haupt-FastAPI-Anwendung mit Endpoints fÃ¼r Historie, Prognosen, Kalenderdaten, Locations und Statusinformationen. EnthÃ¤lt CORS-Setup fÃ¼r lokale Entwicklung.
- `backend/database/redis_client.py`: High-Level-Wrapper fÃ¼r Redis, inkl. Indexierung via Sorted Sets fÃ¼r schnelle Bereichsabfragen.
- `backend/scripts/initial_load.py`: Orchestriert CSV-Importe, ruft Open-Data-API, baut Redis-Indizes und erzeugt initiale Prognosen.
- `backend/data_ingestion/api_fetcher.py`: Holt gestaffelte DatensÃ¤tze aus dem WÃ¼rzburg Open-Data-Portal (monatliche Pagination, Bulk-Insert in Redis).
- `backend/data_ingestion/scheduler.py`: APScheduler-basierter Jobrunner (Fetch neuester Messwerte, generiere ML-Prognosen, Wartung).
- `backend/ML/train.py`: Modelltraining (XGBoost/LightGBM) auf Basis der Daten aus der API. Beinhaltet umfangreiche Feature-Engineering-Funktionen (Zeit, Wetter, Events, Ferien).
- `backend/ML/predict.py`: LÃ¤dt ein trainiertes Modell, generiert 8-Tages-Vorhersagen (unter Einbezug der OpenWeather-Vorhersage) und persistiert sie in Redis (`pedestrian:hourly:prediction:*`).

## API Ãœberblick

| Endpoint | Beschreibung |
| --- | --- |
| `GET /` | Health-Check inkl. Endpoint-Referenzen |
| `GET /api/streets` | Liste aller ZÃ¤hlstellen + Koordinaten |
| `GET /api/pedestrians/historical` | Historische Messdaten fÃ¼r StraÃŸe + Zeitraum |
| `GET /api/pedestrians/detailed/{street}/{date}/{hour}` | Detailansicht inkl. Wetter, Richtungen, Incidents |
| `GET /api/pedestrians/predictions` | Prognosen fÃ¼r StraÃŸe(n) und Zeitraum |
| `GET /api/pedestrians/latest/{street}` | Letztes verfÃ¼gbares Messintervall |
| `GET /api/calendar/{date}` | Feiertage, Schulferien, Vorlesungsperioden, Events |
| `GET /api/events/{date}` | Tagesereignisse mit Details |
| `GET /api/locations(/â€¦)` | ZÃ¤hlstellen-Metadaten (IDs, GeoJSON) |
| `GET /api/holiday/all`, `/api/school-holiday/all`, `/api/lecture/all` | Rohdaten-Exports fÃ¼r ML |
| `GET /api/predictions/status` | Coverage & Zeitstempel der vorhandenen Prognosen |

Swagger und ReDoc sind unter `/docs` bzw. `/redoc` erreichbar.

## Frontend Funktionen

Hauptkomponente: `frontend/components/dashboard.tsx`

- **Filter** (`filters/street-filter.tsx`, `filters/date-filter.tsx`): Auswahl einzelner StraÃŸen oder Aggregation Ã¼ber alle StraÃŸen, Zeitfenster (Tag/Woche/Monat) mit Datumspicker.
- **KPI-Karten** (`statistics/statistics-cards.tsx`): Gesamtanzahl (inkl. live PrognoseauffÃ¼llung), Peak-Analysen (Tag = Peak-Stunde, Woche/Monat = Spitzen-Tag), Trend-Vorhersage fÃ¼r konfigurierbare Zeitfenster, Wetterzusammenfassung.
- **Zeitreihe & Vergleich** (`charts/data-visualization.tsx`): Wechsel zwischen stÃ¼ndlicher Ansicht, Tagesbalken, Vergleich mit Vorperiode (Vortag, Vorwoche, Vormonat, Vorjahr), Integration von Prognosewerten (gestrichelte Linien, Einblendung/Checkboxen).
- **Heatmap** (`charts/heatmap-visualization.tsx`): Tages-/Wochen-Pattern, kombiniert historische Werte mit zukÃ¼nftigen Prognosen.
- **Kalender-Widget** (`calendar/calendar-component.tsx`): Konsolidierte Ansicht aus Feiertagen, Ferien, Vorlesungen und Events (inkl. anstehender Events).
- **Dark-/Lightmode** (`components/theme-toggle.tsx`) und globale Layouts (`app/layout.tsx`, `app/globals.css`).
- **Datenzugriff**: TanStack Query (`components/providers.tsx`, `lib/api.ts`) mit Caching, Fehlerhandling und Utility-Transformationen (`transformToHourlyData`, `transformToDailyData`, etc.).

## Datenpipeline & Machine Learning

1. **Initial Load (`scripts/initial_load.py`)**
   - CSV-Dateien in Redis importieren (`scripts/import_*.py`)
   - Historische Daten Ã¼ber Open-Data-API (Jahr 2024/2025) in Redis laden
   - Redis-Indizes (Sorted Sets) aufbauen (`scripts/build_indexes.py`)
   - Erste Prognosen erzeugen (`ML/predict.run_predictions_and_store`)

2. **RegelmÃ¤ÃŸige Updates (`data_ingestion/scheduler.py`)**
   - `fetch_hourly_updates`: Holt die letzten Stunden Messdaten (pro StraÃŸe) und schreibt sie via `PedestrianRedisClient`.
   - `fetch_predictions`: Triggert `ML/predict.py`, nutzt OpenWeather Forecast (`fetch_weather_forecast`) und verteilt Prognosen auf alle StraÃŸen.

3. **Machine Learning**
   - `ML/train.py`: LÃ¤dt via API alle historischen Daten, reichert sie mit Events, Feiertagen, Vorlesungszeiten und Wettermerkmalen an, trainiert XGBoost/LightGBM und speichert Modell + Feature-Liste.
   - `ML/predict.py`: Nutzt das Modell, generiert `pedestrian:hourly:prediction:{street}:{date}:{hour}` Keys mit TTL und pflegt Status-Endpunkt (`get_prediction_status`).

4. **Redis-Datenschema (Auszug)**
   - Messwerte: `pedestrian:hourly:{street}:{date}:{hour}`
   - Indizes: `pedestrian:index:{street}` (Sorted Set nach Timestamp)
   - Prognosen: `pedestrian:hourly:prediction:{street}:{date}:{hour}`
   - Kalender: `holiday:*`, `school_holiday:*`, `event:*`, `lecture:*`
   - Locations: `location:name:{street}`, `location:id:{id}`

## Entwicklungs-Workflows

### Backend

```bash
# API lokal starten
uvicorn api.main:app --reload --port 8000

# Daten erneut importieren (z.â€¯B. nach CSV-Updates)
python scripts/initial_load.py

# Scheduler in separatem Terminal
python -m data_ingestion.scheduler
```

### Frontend

```bash
cd frontend
npm run lint     # ESLint (nutzt eslint.config.mjs)
npm run build    # Production Check inkl. TypeScript
```

### Tests

Aktuell existieren keine automatisierten Tests im Repo. Empfohlen wird:

- Backend: Pytest + httpx-Client (`FastAPI TestClient`) fÃ¼r zukÃ¼nftige Erweiterungen
- Frontend: Playwright oder Cypress fÃ¼r End-to-End, Vitest/RTL fÃ¼r Komponenten

## Troubleshooting

- **Redis nicht erreichbar**: Verifiziere `REDIS_HOST`/`REDIS_PORT`, prÃ¼fe `docker compose ps`, nutze `docker compose logs redis`.
- **OpenWeather Key fehlt/ungÃ¼ltig**: Prognosen schlagen fehl â‡’ Scheduler-Log prÃ¼fen (`prediction update failed`). GÃ¼ltigen Key in `.env` setzen.
- **Frontend spricht falsche API an**: `frontend/.env.local` prÃ¼fen; `NEXT_PUBLIC_API_URL` muss exakt zum Backend passen.
- **Langsame API beim Initialimport**: `scripts/initial_load.py` ruft Jahr 2024 & 2025 ab. FÃ¼r schnellere Tests kannst du `for year in ["2024", "2025"]` temporÃ¤r reduzieren.
- **Port-Konflikte**: `docker compose` lÃ¤sst Ports konfigurieren (`compose.yaml`). Alternativ lokale Ports anpassen (`PORT=3001 npm run dev`, `uvicorn --port 8080`).
- **Lange Laufzeit ML-Pipeline**: `ML/train.py` holt sÃ¤mtliche Daten via API. FÃ¼r inkrementelles Training Filter/Jahresauswahl anpassen.

## Contributing

Pull-Requests sind willkommen! Bitte beachte:

1. Feature-Branch nach Konvention (`feature/...`, `fix/...`, `docs/...`).
2. Konventionelle Commit-Messages (z.â€¯B. `feat: add prediction overlay`).
3. Linting & Builds lokal ausfÃ¼hren (`npm run lint`, `npm run build`, `uvicorn` Smoke-Test).
4. README oder Dokumentation aktualisieren, falls Verhalten sich Ã¤ndert.
5. Keine Secrets, CSVs oder `node_modules` einchecken.

## WeiterfÃ¼hrende Links

- Next.js Dokumentation: https://nextjs.org/docs
- FastAPI Dokumentation: https://fastapi.tiangolo.com/
- Redis Stack: https://redis.io/docs/
- TanStack Query: https://tanstack.com/query/latest
- shadcn/ui: https://ui.shadcn.com/
- WÃ¼rzburg Open Data Portal: https://data.wuerzburg.de/

Bei Fragen: Logs prÃ¼fen (`docker compose logs -f`), Swagger-UI verwenden oder Redis Insight auf http://localhost:8001 Ã¶ffnen.
# Pedestrian Prediction System

Ein umfassendes System zur Analyse und Vorhersage von PassantenstrÃ¶men in WÃ¼rzburg. Das System kombiniert historische Daten, Wetterbedingungen, Events und Kalenderinformationen, um prÃ¤zise Vorhersagen zu treffen und diese in einem interaktiven Dashboard zu visualisieren.

**Features:**
- ğŸ“Š **Interaktives Dashboard**: Visualisierung von historischen und prognostizierten Passantenzahlen
- ğŸ”® **Predictive Analytics**: ML-basierte Vorhersagen fÃ¼r verschiedene ZeitrÃ¤ume
- ğŸ“… **Kalender-Integration**: BerÃ¼cksichtigung von Feiertagen, Schulferien und Events
- ğŸŒ¤ï¸ **Wetter-Integration**: OpenWeather API fÃ¼r WettereinflÃ¼sse
- ğŸ¨ **Modern UI**: Next.js 15 mit Dark Mode, Responsive Design
- âš¡ **High Performance**: Redis fÃ¼r schnelle Datenabfragen, TanStack Query fÃ¼r optimales Caching

## Inhaltsverzeichnis

- [Architektur](#architektur)
- [Schnellstart](#schnellstart)
  - [Voraussetzungen](#voraussetzungen)
  - [Installation](#installation)
  - [Erste Schritte](#erste-schritte)
  - [Environment Variables](#environment-variables)
- [Projektstruktur](#projektstruktur)
- [Entwicklung](#entwicklung)
  - [Frontend Entwicklung](#frontend-entwicklung)
  - [Container Management](#container-management)
  - [Git Workflow & Kollaboration](#git-workflow--kollaboration)
- [API Endpoints](#api-endpoints)
- [Datenquellen](#datenquellen)
- [Redis Datenstruktur](#redis-datenstruktur)
- [Troubleshooting](#troubleshooting)
  - [Frontend-Probleme](#frontend-probleme)
  - [Backend-Probleme](#backend-probleme)
  - [Podman-spezifische Probleme](#podman-spezifische-probleme)
- [NÃ¤chste Schritte](#nÃ¤chste-schritte)
- [Contributing](#contributing)
- [Support & Kontakt](#support--kontakt)

---

## Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Redis     â”‚â—„â”€â”€â”€â”€â”€â”‚  FastAPI    â”‚â—„â”€â”€â”€â”€â”€â”‚   Next.js   â”‚
â”‚  Database   â”‚      â”‚   Backend   â”‚      â”‚  Frontend   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â–²                    â–²
      â”‚                    â”‚
      â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
      â”‚            â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”  â”Œâ”€-â”€â”€â”€â”´â”€â”€â”€â”€â”
â”‚ Data Loader â”‚ â”‚  Cron  â”‚  â”‚ ML Model â”‚
â”‚ (einmalig)  â”‚ â”‚  Jobs  â”‚  â”‚ Training â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Komponenten:**
- **Redis**: Datenbank fÃ¼r Zeitreihen und Features
- **FastAPI**: REST API fÃ¼r Datenabfragen und Datenverarbeitung
- **Next.js Frontend**: Moderne React-Anwendung mit App Router, TypeScript und TanStack Query
- **Data Loader**: Initiales Laden aller CSV-Daten
- **Scheduler**: StÃ¼ndliche Updates von API-Daten
- **ML Training**: TÃ¤gliches Training der Vorhersagemodelle

**Tech Stack:**
- **Backend**: Python, FastAPI, Redis
- **Frontend**: Next.js 15, React 19, TypeScript, Tailwind CSS, shadcn/ui
- **Container**: Docker / Podman mit Compose

---

## Schnellstart

### Voraussetzungen

**Container Runtime:**
- Docker & Docker Compose **oder** Podman & Podman Compose
  - [Podman Installation](https://podman.io/getting-started/installation) (Alternative zu Docker)

**FÃ¼r Frontend-Entwicklung:**
- [Node.js LTS](https://nodejs.org/) (v20.x oder hÃ¶her empfohlen)
- npm oder pnpm (kommt mit Node.js)

**Optional:**
- OpenWeather API Key fÃ¼r Wettervorhersagen
- Git fÃ¼r Versionskontrolle

### Installation

```bash
# Repository klonen
git clone <repository-url>
cd PedestrainDashboard

# CSV-Dateien im backend/data/ Ordner platzieren
mkdir -p backend/data
# (Dateien manuell in backend/data/ kopieren)

# .env Datei umbenennen von **.env.local** zu **.env**
OPENWEATHER_API_KEY=your_api_key_here
REDIS_HOST=redis
REDIS_PORT=6379

# Backend starten (baut Container, startet Redis, importiert Daten)
podman compose up -d --build

# Frontend Dependencies installieren
cd frontend
npm install

# Frontend .env.local erstellen:
NEXT_PUBLIC_API_URL=http://localhost:8000

# Frontend im Development-Modus starten
npm run dev

# Logs vom Backend verfolgen (in Podman Desktop)

**Alternative mit Docker:**
```bash
# Ersetze 'podman compose' mit 'docker-compose' in allen Befehlen
docker-compose up -d --build
```

### Erste Schritte

Nach erfolgreicher Installation sind folgende Services verfÃ¼gbar:

```bash
# Frontend Ã¶ffnen
open http://localhost:3000

# Backend API testen
curl http://localhost:8000/

# Swagger UI Ã¶ffnen (API Dokumentation)
open http://localhost:8000/docs

# Redis Insight Ã¶ffnen (Datenbank Explorer)
open http://localhost:8001
```

**VerfÃ¼gbare URLs:**
- **Frontend Dashboard**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Dokumentation (Swagger)**: http://localhost:8000/docs
- **API Dokumentation (ReDoc)**: http://localhost:8000/redoc
- **Redis Insight**: http://localhost:8001

### Environment Variables

**Backend (.env im Root-Verzeichnis):**
```bash
# OpenWeather API (optional, fÃ¼r Wettervorhersagen)
OPENWEATHER_API_KEY=your_api_key_here

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
```

**Frontend (frontend/.env.local):**
```bash
# Backend API URL
NEXT_PUBLIC_API_URL=http://localhost:8000

# Optional: Analytics, Monitoring, etc.
# NEXT_PUBLIC_ANALYTICS_ID=your_id_here
```

**Hinweise:**
- `.env` Dateien nicht ins Git committen (bereits in `.gitignore`)
- FÃ¼r Production: Sichere Werte verwenden
- `NEXT_PUBLIC_*` Prefix fÃ¼r Ã¶ffentlich zugÃ¤ngliche Variablen im Frontend

---

## Projektstruktur

```
PedestrainDashboard-main/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI Endpoints
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/                    # CSV Dateien (nicht im Git)
â”‚   â”‚   â”œâ”€â”€ bavarian_public_holidays_daily.csv
â”‚   â”‚   â”œâ”€â”€ bavarian_public_holidays.csv
â”‚   â”‚   â”œâ”€â”€ bavarian_school_holidays_daily.csv
â”‚   â”‚   â”œâ”€â”€ bavarian_school_holidays.csv
â”‚   â”‚   â”œâ”€â”€ events_daily.csv
â”‚   â”‚   â”œâ”€â”€ events.csv
â”‚   â”‚   â”œâ”€â”€ lectures_daily.csv
â”‚   â”‚   â”œâ”€â”€ lectures.csv
â”‚   â”‚   â”œâ”€â”€ counterGeoLocations.csv
â”‚   â”‚   â””â”€â”€ dataAllStreets.csv
â”‚   â”œâ”€â”€ data_ingestion/
â”‚   â”‚   â”œâ”€â”€ api_fetcher.py       # Holt Daten von API
â”‚   â”‚   â”œâ”€â”€ weather_fetcher.py   # OpenWeather Integration
â”‚   â”‚   â””â”€â”€ scheduler.py         # Cron Jobs
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ redis_client.py      # Redis Wrapper
â”‚   â”œâ”€â”€ ML/
â”‚   â”‚   â”œâ”€â”€ train.py             # Model Training
â”‚   â”‚   â”œâ”€â”€ predict.py           # Predictions
â”‚   â”‚   â””â”€â”€ evaluate.py          # Model Evaluation
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ initial_load.py      # Master Import Script
â”‚   â”‚   â”œâ”€â”€ import_*.py          # Einzelne Import Scripts
â”‚   â”‚   â””â”€â”€ build_indexes.py     # Index Building
â”‚   â”œâ”€â”€ config.py                # Configuration
â”‚   â”œâ”€â”€ requirements.txt         # Python Dependencies
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/                     # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ page.tsx             # Dashboard Page
â”‚   â”‚   â”œâ”€â”€ layout.tsx           # Root Layout
â”‚   â”‚   â”œâ”€â”€ globals.css          # Global Styles
â”‚   â”‚   â””â”€â”€ favicon.ico
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ dashboard.tsx        # Main Dashboard Component
â”‚   â”‚   â”œâ”€â”€ charts/
â”‚   â”‚   â”‚   â””â”€â”€ data-visualization.tsx  # Chart Components
â”‚   â”‚   â”œâ”€â”€ filters/
â”‚   â”‚   â”‚   â”œâ”€â”€ date-filter.tsx         # Date Selection
â”‚   â”‚   â”‚   â””â”€â”€ street-filter.tsx       # Street Selection
â”‚   â”‚   â”œâ”€â”€ statistics/
â”‚   â”‚   â”‚   â””â”€â”€ statistics-cards.tsx    # Stats Display
â”‚   â”‚   â”œâ”€â”€ calendar/
â”‚   â”‚   â”‚   â””â”€â”€ calendar-component.tsx  # Calendar Widget
â”‚   â”‚   â”œâ”€â”€ ui/                  # shadcn/ui Components
â”‚   â”‚   â”‚   â”œâ”€â”€ button.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ card.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ select.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ providers.tsx        # React Query Provider
â”‚   â”‚   â””â”€â”€ theme-toggle.tsx     # Dark Mode Toggle
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api.ts               # API Client
â”‚   â”‚   â”œâ”€â”€ types.ts             # TypeScript Types
â”‚   â”‚   â”œâ”€â”€ utils.ts             # Utility Functions
â”‚   â”‚   â””â”€â”€ hooks/
â”‚   â”‚       â””â”€â”€ use-pedestrian-data.ts  # Data Fetching Hook
â”‚   â”œâ”€â”€ public/                  # Static Assets
â”‚   â”œâ”€â”€ package.json             # Node Dependencies
â”‚   â”œâ”€â”€ tsconfig.json            # TypeScript Config
â”‚   â”œâ”€â”€ next.config.ts           # Next.js Config
â”‚   â””â”€â”€ tailwind.config.ts       # Tailwind CSS Config
â”œâ”€â”€ compose.yaml                 # Docker Compose Configuration
â”œâ”€â”€ .env                         # Environment Variables
â””â”€â”€ README.md
```

### Frontend Architektur

Das Frontend ist mit Next.js 15 und dem App Router aufgebaut:

**Komponentenstruktur:**
```
Dashboard (Main Component)
â”œâ”€â”€ DateFilter          â†’ Datumsauswahl mit Calendar Picker
â”œâ”€â”€ StreetFilter        â†’ Dropdown fÃ¼r StraÃŸenauswahl
â”œâ”€â”€ StatisticsCards     â†’ KPI-Anzeigen (Durchschnitt, Peak, Trend)
â”œâ”€â”€ DataVisualization   â†’ Recharts fÃ¼r Diagramme
â”‚   â”œâ”€â”€ LineChart       â†’ Zeitverlauf
â”‚   â”œâ”€â”€ BarChart        â†’ Stundenvergleich
â”‚   â””â”€â”€ AreaChart       â†’ Predictions mit Confidence Interval
â””â”€â”€ CalendarComponent   â†’ Event-Ãœbersicht
```

**State Management & Data Flow:**
```
TanStack Query (React Query)
â”œâ”€â”€ usePedestrianData() â†’ Custom Hook fÃ¼r alle API Calls
â”œâ”€â”€ Cache-Strategie      â†’ 5 Min Stale Time, Auto-Refetch
â””â”€â”€ Optimistic Updates   â†’ Sofortige UI-Updates
```

**API-Integration:**
```typescript
// lib/api.ts - Zentrale API-Client
export const fetchHistoricalData = async (street: string, dateRange: DateRange)
export const fetchCurrentData = async (street: string)
export const fetchPredictions = async (street: string, hours: number)
export const fetchStatistics = async (street: string, daysBack: number)
```

**Styling:**
- **Tailwind CSS**: Utility-First Styling
- **shadcn/ui**: Accessible, customizable UI-Komponenten
- **next-themes**: Dark/Light Mode mit System-Preference
- **CSS Variables**: Konsistentes Theming

---

## Entwicklung

### Frontend Entwicklung

**Development Server starten:**
```bash
cd frontend
npm run dev
```

Das Frontend lÃ¤uft auf http://localhost:3000 mit Hot Reload.

**VerfÃ¼gbare Scripts:**
```bash
npm run dev        # Development Server (Port 3000)
npm run build      # Production Build
npm run start      # Production Server starten
npm run lint       # ESLint ausfÃ¼hren
```

**Wichtige Technologien:**
- **Next.js 15**: App Router, Server Components, Turbopack
- **React 19**: Neueste Features
- **TypeScript**: Type-safe Development
- **TanStack Query**: Data Fetching & Caching
- **Tailwind CSS**: Utility-First Styling
- **shadcn/ui**: Wiederverwendbare UI-Komponenten
- **Recharts**: Datenvisualisierung
- **next-themes**: Dark Mode Support

**Komponenten hinzufÃ¼gen:**
```bash
# shadcn/ui Komponenten installieren
npx shadcn@latest add <component-name>

# Beispiel:
npx shadcn@latest add dialog
npx shadcn@latest add dropdown-menu
```

### Container Management

```bash
# Alle Services starten
docker-compose up -d

# Einzelnen Service neu starten
docker-compose restart api
docker-compose restart scheduler

# Mit Rebuild (nach Code-Ã„nderungen)
docker-compose up -d --build api

# Alle Services stoppen
docker-compose down

# Mit Datenbank-LÃ¶schung
docker-compose down -v
```

### Logs anschauen

```bash
# Alle Logs live
docker-compose logs -f

# Nur API
docker-compose logs -f api

# Letzte 100 Zeilen
docker-compose logs --tail=100 api

# Data Loader (auch wenn gestoppt)
docker-compose logs data_loader
```

### Daten neu importieren

```bash
# Nur fehlende Daten importieren
docker-compose run --rm data_loader

# Alles lÃ¶schen und neu importieren
docker-compose down -v
docker-compose up -d
```

### In Container einsteigen

```bash
# API Container
docker-compose exec api bash

# Redis CLI
docker-compose exec redis redis-cli

# Python Shell im Container
docker-compose exec api python
```

### Redis Daten prÃ¼fen

```bash
docker-compose exec redis redis-cli

# Im Redis CLI:
> KEYS pedestrian:hourly:KaiserstraÃŸe:*
> HGETALL pedestrian:hourly:KaiserstraÃŸe:2019-04-02:18
> SMEMBERS holidays:all_dates
> DBSIZE
```

### Git Workflow & Kollaboration

**Repository Setup:**
```bash
# Repository klonen
git clone <repository-url>
cd PedestrainDashboard-main

# Upstream remote hinzufÃ¼gen (falls Fork)
git remote add upstream <original-repository-url>
```

**Branch-Strategie:**

Wir verwenden einen Feature-Branch-Workflow:

```bash
# Immer vom aktuellen main starten
git checkout main
git pull origin main

# Neuen Feature-Branch erstellen
git checkout -b <branch-typ>/<kurze-beschreibung>
```

**Branch-Naming Convention:**

Format: `<typ>/<kurze-beschreibung>`

**Typen:**
- `feature/` - Neue Features (z.B. `feature/user-authentication`)
- `fix/` - Bugfixes (z.B. `fix/api-error-handling`)
- `refactor/` - Code-Refactoring (z.B. `refactor/redis-client`)
- `docs/` - Dokumentation (z.B. `docs/update-readme`)
- `style/` - Styling-Ã„nderungen (z.B. `style/dashboard-layout`)
- `test/` - Tests hinzufÃ¼gen (z.B. `test/api-endpoints`)
- `chore/` - Maintenance (z.B. `chore/update-dependencies`)

**Beispiele:**
```bash
git checkout -b feature/weather-predictions
git checkout -b fix/date-filter-bug
git checkout -b docs/api-documentation
git checkout -b refactor/database-queries
```

**Entwicklungs-Workflow:**
```bash
# Ã„nderungen machen...

# Status prÃ¼fen
git status

# Dateien zum Staging hinzufÃ¼gen
git add .

# Commit mit aussagekrÃ¤ftiger Nachricht
git commit -m "feat: add weather prediction endpoint"

# Branch pushen
git push origin <branch-name>

# Falls Branch noch nicht auf Remote existiert:
git push -u origin <branch-name>
```

**Commit Message Convention:**

Format: `<typ>: <kurze beschreibung>`

**Typen:**
- `feat:` - Neues Feature
- `fix:` - Bugfix
- `docs:` - DokumentationsÃ¤nderung
- `style:` - Code-Formatierung, Styling
- `refactor:` - Code-Umstrukturierung
- `test:` - Tests hinzufÃ¼gen/Ã¤ndern
- `chore:` - Maintenance, Dependencies

**Beispiele:**
```bash
git commit -m "feat: add date range filter component"
git commit -m "fix: resolve API connection timeout"
git commit -m "docs: update installation instructions"
git commit -m "refactor: improve data fetching logic"
```

**Pull Request erstellen:**

1. Push deinen Branch zu GitHub
2. Gehe zu GitHub und erstelle einen Pull Request
3. Beschreibe deine Ã„nderungen ausfÃ¼hrlich
4. Verlinke relevante Issues
5. Warte auf Code Review
6. Nimm Feedback auf und update bei Bedarf

**Branch aktuell halten:**
```bash
# Main Branch updaten
git checkout main
git pull origin main

# Ã„nderungen in deinen Branch mergen
git checkout <dein-branch>
git merge main

# Oder mit rebase (sauberer)
git rebase main
```

**Best Practices:**
- âœ… Kleine, fokussierte Commits
- âœ… AussagekrÃ¤ftige Commit-Messages
- âœ… RegelmÃ¤ÃŸig pushen
- âœ… Branch vor PR mit main synchronisieren
- âœ… Code Reviews durchfÃ¼hren
- âœ… Tests schreiben fÃ¼r neue Features
- âŒ Nie direkt auf main pushen
- âŒ Keine riesigen Commits mit vielen Ã„nderungen
- âŒ Keine generierten Dateien committen (node_modules, .env, etc.)

**Hilfreiche Befehle:**
```bash
# Ã„nderungen verwerfen
git checkout -- <datei>
git restore <datei>

# Letzten Commit rÃ¼ckgÃ¤ngig machen (lokal)
git reset --soft HEAD~1

# Branch lÃ¶schen (lokal)
git branch -d <branch-name>

# Branch lÃ¶schen (remote)
git push origin --delete <branch-name>

# Stash (Ã„nderungen temporÃ¤r speichern)
git stash
git stash pop

# Commit-Historie ansehen
git log --oneline --graph
```

---

## API Endpoints

### Base URL
`http://localhost:8000`

### Dokumentation
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Wichtige Endpoints

**Health Check**
```bash
GET /
```

**StraÃŸen abrufen**
```bash
GET /api/streets
```

**Historische Daten**
```bash
GET /api/pedestrians/historical?street=KaiserstraÃŸe&start_date=2019-04-02&end_date=2019-04-05
```

**Aktuelle Daten**
```bash
GET /api/pedestrians/current?street=KaiserstraÃŸe
```

**Predictions**
```bash
GET /api/pedestrians/predictions?street=KaiserstraÃŸe&hours=24
```

**Statistiken**
```bash
GET /api/statistics/KaiserstraÃŸe?days_back=30
```

**Kalender-Informationen (kombiniert)**
```bash
GET /api/calendar/2019-04-02
```

**Events**
```bash
GET /api/events/2019-03-03
```

**Locations (Geodaten)**
```bash
GET /api/locations
GET /api/locations/KaiserstraÃŸe
```

**StraÃŸen-Vergleich**
```bash
GET /api/compare?date=2019-04-02&hour=18
```

---

## Datenquellen

### Erforderliche CSV-Dateien

Alle Dateien mÃ¼ssen in `backend/data/` liegen:

| Datei | Beschreibung | Zeilen | Format |
|-------|--------------|--------|--------|
| `bavarian_public_holidays_daily.csv` | TÃ¤gliche Feiertage | ~365/Jahr | date,public_holiday,nationwide |
| `bavarian_public_holidays.csv` | Detaillierte Feiertage | ~15/Jahr | date,name,regionalScope,... |
| `bavarian_school_holidays_daily.csv` | TÃ¤gliche Schulferien | ~365/Jahr | date,school_holiday |
| `bavarian_school_holidays.csv` | Ferienperioden | ~7/Jahr | name,startDate,endDate,... |
| `events_daily.csv` | TÃ¤gliche Events | ~8760/Jahr | date,event,concert |
| `events.csv` | Event-Details | ~100/Jahr | name,start,end,concert |
| `lectures_daily.csv` | Vorlesungszeiten tÃ¤glich | ~365/Jahr | date,lecture_period_jmu |
| `lectures.csv` | Vorlesungsperioden | ~10/Jahr | start,end,jmu,thws |
| `counterGeoLocations.csv` | ZÃ¤hlstationen-Geodaten | 3 | ID,streetname,GeoShape,... |
| `dataAllStreets.csv` | Historische Passantendaten | ~26k | id,streetname,date,hour,... |

### Externe APIs

**Passantendaten API**
- Base URL: `https://data.wuerzburg.de`
- Endpoint: `/api/explore/v2.1/catalog/datasets/passantenzaehlung_stundendaten/records`
- Wird automatisch stÃ¼ndlich abgerufen

**OpenWeather API** (optional)
- FÃ¼r Wettervorhersagen
- API Key in `.env` setzen

---

## Redis Datenstruktur

### Passantendaten
```
pedestrian:hourly:{street}:{date}:{hour} â†’ Hash
```

### Kalender-Features
```
holiday:{date} â†’ Hash
holiday:detail:{date} â†’ Hash
school_holiday:{date} â†’ Hash
school_holiday:day:{date} â†’ Hash
event:detail:hour:{date}:{hour} â†’ Hash
lecture:detail:{date} â†’ Hash
```

### Indizes (Sets fÃ¼r schnelle Lookups)
```
holidays:all_dates â†’ Set
school_holidays:all â†’ Set
events:all_dates â†’ Set
lectures:jmu:detailed â†’ Set
```

### Locations
```
location:id:{id} â†’ Hash
location:name:{street} â†’ Hash
```

### Predictions
```
prediction:{street}:{date}:{hour} â†’ Hash (TTL: 30 Tage)
```

---

## Troubleshooting

### Frontend-Probleme

**Port 3000 bereits belegt:**
```bash
# Finde Prozess auf Port 3000
lsof -i :3000
# Prozess beenden oder anderen Port verwenden
PORT=3001 npm run dev
```

**API-Verbindung schlÃ¤gt fehl:**
```bash
# PrÃ¼fe ob Backend lÃ¤uft
curl http://localhost:8000/

# CORS-Fehler? PrÃ¼fe backend/api/main.py
# Stelle sicher dass CORS richtig konfiguriert ist

# .env.local im Frontend prÃ¼fen
cat frontend/.env.local
```

**Node Modules Probleme:**
```bash
cd frontend
rm -rf node_modules package-lock.json
npm install
```

**TypeScript Fehler:**
```bash
cd frontend
npm run build  # Zeigt alle TS-Fehler
npx tsc --noEmit  # Type-Check ohne Build
```

### Backend-Probleme

**Port bereits belegt:**
```bash
# Finde Prozess auf Port 8000
lsof -i :8000

# Oder Ã¤ndere Port in compose.yaml
ports:
  - "8080:8000"  # Extern 8080, intern 8000
```

**Redis Verbindung fehlgeschlagen:**
```bash
# PrÃ¼fe Redis
docker-compose exec redis redis-cli ping
# Sollte "PONG" zurÃ¼ckgeben

# Logs prÃ¼fen
docker-compose logs redis
```

**Data Loader zeigt keine Logs:**
```bash
# Manuell ausfÃ¼hren
docker-compose run --rm data_loader

# Oder im Vordergrund
docker-compose up data_loader
```

**Python Module nicht gefunden:**
```bash
# Container neu bauen
docker-compose build --no-cache api
docker-compose up -d
```

**API lÃ¤dt Ã„nderungen nicht:**
```bash
# PrÃ¼fe ob --reload aktiv ist
docker-compose logs api | grep reload

# Manuell neu starten
docker-compose restart api
```

**Daten importieren dauert zu lange:**
```bash
# API-Limit erreicht? PrÃ¼fe Logs
docker-compose logs data_loader | grep Error

# Reduziere Jahre in initial_load.py
# Ã„ndere: for year in ["2024", "2025"]
# Zu: for year in ["2025"]
```

### Podman-spezifische Probleme

**Podman Compose nicht gefunden:**
```bash
# Installiere podman-compose
pip3 install podman-compose

# Oder verwende podman-compose als Plugin
podman compose up -d
```

**Permission-Probleme:**
```bash
# Rootless Mode aktivieren
podman system migrate

# SELinux Labels (Linux only)
# FÃ¼ge :Z zu Volumes hinzu in compose.yaml
volumes:
  - ./backend:/app:Z
```

---

## NÃ¼tzliche Befehle

### Entwicklung

```bash
# Hot Reload funktioniert automatisch fÃ¼r API
# Bei Scheduler-Ã„nderungen:
docker-compose restart scheduler

# Requirements hinzugefÃ¼gt?
docker-compose up -d --build api scheduler

# Alle Container neu bauen
docker-compose build --no-cache
```

### Debugging

```bash
# Python Shell im Container
docker-compose exec api python

# Redis Daten inspizieren
docker-compose exec redis redis-cli
> KEYS *
> DBSIZE
> MEMORY USAGE pedestrian:hourly:KaiserstraÃŸe:2019-04-02:18

# Container Stats
docker stats
```

### Produktion

```bash
# Ohne Volume Mounts fÃ¼r Production
# In docker-compose.yml volumes: auskommentieren

# Mit resource limits
docker-compose up -d --scale scheduler=1 --scale api=3
```

---

## NÃ¤chste Schritte

**Backend:**
- [ ] ML Model Training & Predictions implementieren (`ML/train.py`, `ML/predict.py`)
- [ ] Weather Fetcher vervollstÃ¤ndigen (`data_ingestion/weather_fetcher.py`)
- [ ] Scheduler Jobs aktivieren (stÃ¼ndlich, tÃ¤glich)
- [ ] API Tests schreiben
- [ ] Performance Optimierung (Caching, Query-Optimierung)

**Frontend:**
- [ ] Predictions-Visualisierung erweitern
- [ ] Interaktive Karten-Integration (Leaflet/Mapbox)
- [ ] Export-Funktionen (CSV, PDF)
- [ ] Responsive Design verbessern
- [ ] Accessibility (a11y) Tests
- [ ] End-to-End Tests (Playwright/Cypress)

**DevOps:**
- [ ] CI/CD Pipeline (GitHub Actions)
- [ ] Docker Compose fÃ¼r Production
- [ ] Monitoring & Logging (Prometheus, Grafana)
- [ ] Deployment-Strategie (Docker Swarm / Kubernetes)
- [ ] Backup-Strategie fÃ¼r Redis
- [ ] SSL/TLS Zertifikate fÃ¼r Production

**Dokumentation:**
- [ ] API Dokumentation erweitern
- [ ] Architektur-Diagramme aktualisieren
- [ ] Entwickler-Onboarding-Guide
- [ ] Deployment-Guide

---

## Contributing

BeitrÃ¤ge sind willkommen! Bitte folge dem [Git Workflow](#git-workflow--kollaboration) Abschnitt.

**Schritte fÃ¼r Contributions:**

1. **Fork** das Repository
2. **Clone** deinen Fork
3. **Branch** erstellen: `git checkout -b feature/deine-feature`
4. **Ã„nderungen** machen und committen
5. **Tests** ausfÃ¼hren (falls vorhanden)
6. **Push** zu deinem Fork: `git push origin feature/deine-feature`
7. **Pull Request** erstellen auf GitHub

**Code Style:**
- Python: PEP 8, Black Formatter
- TypeScript/React: ESLint + Prettier
- Commits: Conventional Commits Format

**Vor dem Pull Request:**
- [ ] Code lÃ¤uft lokal ohne Fehler
- [ ] ESLint/Type-Checks passieren
- [ ] README bei Bedarf aktualisiert
- [ ] Commit-Messages folgen Convention

---

## Support & Kontakt

Bei Problemen oder Fragen:

**Debugging-Checkliste:**
1. Logs prÃ¼fen: `docker-compose logs -f`
2. Redis prÃ¼fen: `docker-compose exec redis redis-cli`
3. Container Status: `docker-compose ps`
4. Swagger UI fÃ¼r API-Tests: http://localhost:8000/docs
5. Frontend Console (Browser DevTools) auf Fehler prÃ¼fen

**Hilfreiche Links:**
- [Next.js Dokumentation](https://nextjs.org/docs)
- [FastAPI Dokumentation](https://fastapi.tiangolo.com/)
- [Redis Dokumentation](https://redis.io/docs/)
- [TanStack Query Docs](https://tanstack.com/query/latest)
- [shadcn/ui Components](https://ui.shadcn.com/)

---